{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir(r\"C:\\Users\\Gerrit\\Desktop\\Data Science Portfolio\\data\")\n",
    "\n",
    "jeopardy = pd.read_csv(\"jeopardy.csv\")\n",
    "jeopardy.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Making all columns lowercase and removing spaces\n",
    "columns = []\n",
    "for col in jeopardy.columns:\n",
    "    col = col.replace(\" \",\"\").lower()\n",
    "    columns.append(col)\n",
    "    \n",
    "jeopardy.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_text(string):\n",
    "    string = string.lower()\n",
    "    string = re.sub(\"[^A-Za-z0-9\\s]\",\"\",string)\n",
    "    return string\n",
    "\n",
    "jeopardy[\"clean_question\"] = jeopardy[\"question\"].apply(normalize_text)\n",
    "\n",
    "jeopardy[\"clean_answer\"] = jeopardy[\"answer\"].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_values(string):\n",
    "    string = re.sub(\"[^A-Za-z0-9]+\",\"\",string)\n",
    "    try:\n",
    "        string = int(string)\n",
    "    except Exception:\n",
    "        string = 0\n",
    "    return string\n",
    "\n",
    "jeopardy[\"clean_values\"] = jeopardy[\"value\"].apply(normalize_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jeopardy[\"airdate\"] = pd.to_datetime(jeopardy[\"airdate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to figure out whether to study past questions, study general knowledge, or not study it all, it would be helpful to figure out two things:\n",
    "\n",
    "How often the answer is deducible from the question.\n",
    "\n",
    "How often new questions are repeats of older questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Count how many times terms in clean_answer occur in clean_question\n",
    "def count_matches(row):\n",
    "    split_answer = row[\"clean_answer\"].split(\" \")\n",
    "    split_question = row[\"clean_question\"].split(\" \")\n",
    "    if \"the\" in split_answer:\n",
    "        split_answer.remove(\"the\")\n",
    "    if len(split_answer) == 0:\n",
    "            return 0\n",
    "    match_count = 0\n",
    "    for char in split_answer:\n",
    "        if char in split_question:\n",
    "            match_count += 1\n",
    "    return match_count/len(split_answer)\n",
    "\n",
    "jeopardy[\"answers_in_question\"] = jeopardy.apply(count_matches, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0604932570693\n"
     ]
    }
   ],
   "source": [
    "mean_answers_in_questions = jeopardy[\"answers_in_question\"].mean()\n",
    "print(mean_answers_in_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer only appears in the question about 6% of the time. This isn't a huge number, and means that we probably can't just hope that hearing a question will enable us to figure out the answer. We'll probably have to study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recycled Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say you want to investigate how often new questions are repeats of older ones. You can't completely answer this, because you only have about 10% of the full Jeopardy question dataset, but you can investigate it at least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69087373156719623"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_overlap = []\n",
    "terms_used = set()\n",
    "for i, row in jeopardy.iterrows():\n",
    "    split_question = row[\"clean_question\"].split(\" \")\n",
    "    split_question = [a for a in split_question if len(a) > 5]\n",
    "    match_count = 0\n",
    "    for word in split_question:\n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "    for word in split_question:\n",
    "        terms_used.add(word)\n",
    "    if len(split_question) > 0:\n",
    "        match_count /= len(split_question)\n",
    "    question_overlap.append(match_count)\n",
    "    \n",
    "jeopardy[\"question_overlap\"] = question_overlap\n",
    "jeopardy[\"question_overlap\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from the analysis above that terms appear in both the question and the answer about 70% of the time.  This only looks at a small set of questions, and it doesn't look at phrases, it looks at single terms. This makes it relatively insignificant, but it does mean that it's worth looking more into the recycling of questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low Value Vs High Value Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can actually figure out which terms correspond to high-value questions using a chi-squared test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def determine_value(row):\n",
    "    value = 0\n",
    "    if row[\"clean_values\"] > 800:\n",
    "        value = 1\n",
    "    return value\n",
    "\n",
    "jeopardy[\"high_value\"] = jeopardy.apply(determine_value, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (0, 1), (2, 1), (0, 1), (0, 1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_usage(term):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for i, row in jeopardy.iterrows():\n",
    "        if term in row[\"clean_question\"].split(\" \"):\n",
    "            if row[\"high_value\"] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count\n",
    "\n",
    "comparison_terms = list(terms_used)[:5]\n",
    "observed_expected = []\n",
    "for term in comparison_terms:\n",
    "    observed_expected.append(count_usage(term))\n",
    "\n",
    "observed_expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the Chi-Squared Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of significant results: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40196284612688399,\n",
       " 0.40196284612688399,\n",
       " 2.1177104383031944,\n",
       " 0.40196284612688399,\n",
       " 0.40196284612688399]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "\n",
    "high_value_count = len(jeopardy[jeopardy[\"high_value\"] == 1])\n",
    "low_value_count = len(jeopardy[jeopardy[\"high_value\"] == 0])\n",
    "chi_squared = []\n",
    "pvalues = []\n",
    "\n",
    "for each in observed_expected:\n",
    "    total = sum(each)\n",
    "    total_prop = total/jeopardy.shape[0]\n",
    "    exp_high = total_prop*high_value_count\n",
    "    exp_low = total_prop*low_value_count\n",
    "    \n",
    "    obs = np.asarray([each[0],each[1]])\n",
    "    exp = np.asarray([exp_high,exp_low])\n",
    "    chisq, pvalue = chisquare(obs,exp)\n",
    "    chi_squared.append(chisq)\n",
    "    pvalues.append(pvalue)\n",
    "\n",
    "significant_pvalues = [x for x in pvalues if x <= .05]\n",
    "print(\"Number of significant results:\", len(significant_pvalues))\n",
    "\n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, there are no statistically significant differences in high_count and low_count. Additionally, the frequencies were all lower than 5, so the chi-squared test isn't as valid. It would be better to run this test with only terms that have higher frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some potential next steps:\n",
    "\n",
    "Find a better way to eliminate non-informative words than just removing words that are less than 6 characters long. Some ideas:\n",
    "Manually create a list of words to remove, like the, than, etc.\n",
    "Find a list of stopwords to remove.\n",
    "Remove words that occur in more than a certain percentage (like 5%) of questions.\n",
    "\n",
    "Perform the chi-squared test across more terms to see what terms have larger differences. This is hard to do currently because the code is slow, but here are some ideas:\n",
    "Use the apply method to make the code that calculates frequencies more efficient.\n",
    "Only select terms that have high frequencies across the dataset, and ignore the others.\n",
    "\n",
    "Look more into the Category column and see if any interesting analysis can be done with it. Some ideas:\n",
    "See which categories appear the most often.\n",
    "Find the probability of each category appearing in each round.\n",
    "\n",
    "Use the whole Jeopardy dataset (available here: https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file?st=iscjul8i&sh=140c8205) instead of the subset we used in this mission.\n",
    "\n",
    "Use phrases instead of single words when seeing if there's overlap between questions. Single words don't capture the whole context of the question well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
